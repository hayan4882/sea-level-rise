# streamlit_app.py
# Streamlit ì•±: í•œêµ­ì–´ UIë¡œ ê³µì‹ ê³µê°œ ë°ì´í„° ê¸°ë°˜ í•´ìˆ˜ë©´ ìƒìŠ¹ ëŒ€ì‹œë³´ë“œ + ì‚¬ìš©ì ì…ë ¥(í”„ë¡¬í”„íŠ¸ ê¸°ë°˜) ëŒ€ì‹œë³´ë“œ
# ì‘ì„±ì: AI (Streamlit + GitHub Codespaces-ready)
# ì¶œì²˜(ì˜ˆì‹œ, ì½”ë“œ ì£¼ì„ìœ¼ë¡œ ëª…í™•íˆ ë‚¨ê¹€):
# - NASA/JPL Global Mean Sea Level (GMSL) & altimetry resources: https://sealevel.jpl.nasa.gov/ and https://podaac.jpl.nasa.gov/dataset/NASA_SSH_GMSL_INDICATOR  (ë°ì´í„° ë‹¤ìš´ë¡œë“œ í˜ì´ì§€)
# - PSMSL (Permanent Service for Mean Sea Level) tide gauge ë°ì´í„°: https://psmsl.org/ (ê°œë³„ ê´€ì¸¡ì†Œ ë° ì „ì²´ ë°ì´í„°)
# - NOAA Sea Level Trends / Sea Level Rise Viewer data: https://coast.noaa.gov/slrdata/ and https://tidesandcurrents.noaa.gov/sltrends/
# - ëŒ€í•œë¯¼êµ­(êµ­ë‚´) í•´ìˆ˜ë©´ ê´€ë ¨ ì˜¤í”ˆë°ì´í„°(ì˜ˆì‹œ): https://www.data.go.kr/ (êµ­ë¦½í•´ì–‘ì¡°ì‚¬ì› ê´€ë ¨ API ë° íŒŒì¼, ex: í•´ìˆ˜ë©´ ì£¼ê°„ ì „ë§ í†µê³„)
#
# ìœ„ URLë“¤ì€ ë°ì´í„° ì†ŒìŠ¤ ìœ„ì¹˜(ì°¸ê³ )ì´ë©°, ì‹¤ì œ ìë™ ë‹¤ìš´ë¡œë“œê°€ ë¶ˆê°€í•˜ê±°ë‚˜ API ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë©ë‹ˆë‹¤.
# (ìš”êµ¬ì‚¬í•­) API ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ -> ì‹¤íŒ¨í•˜ë©´ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ë©° ì‚¬ìš©ìì—ê²Œ í•œêµ­ì–´ ì•ˆë‚´ í‘œì‹œí•©ë‹ˆë‹¤.

import io
import time
from datetime import datetime, date
from typing import Tuple

import requests
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px

# -------------------------
# ì„¤ì •: ë¡œì»¬ 'ì˜¤ëŠ˜' ê¸°ì¤€ (ê°œë°œì ì§€ì¹¨: Asia/Seoul íƒ€ì„ì¡´, í˜„ì¬ ë‚ ì§œ 2025-09-18)
# ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” datetime.today() ì‚¬ìš©í•˜ë˜ ì—¬ê¸°ì„œëŠ” ì‹œìŠ¤í…œ ì‹œê°„ ì‚¬ìš©
TODAY = pd.to_datetime(datetime.now().date())

# Pretendard í°íŠ¸ ì‹œë„: /fonts/Pretendard-Bold.ttf (ì—†ìœ¼ë©´ ë¬´ì‹œ)
PRETENDARD_PATH = "/fonts/Pretendard-Bold.ttf"

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í•´ìˆ˜ë©´ ìƒìŠ¹ ëŒ€ì‹œë³´ë“œ / ì²­ì†Œë…„ ì˜í–¥ ë¶„ì„",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ì „ì—­ ìŠ¤íƒ€ì¼(ì‹œë„): Pretendard ì ìš© (ë¸Œë¼ìš°ì €ì—ì„œ ë¡œì»¬ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ë¬´ì‹œ)
def inject_global_css():
    css = ""
    try:
        with open(PRETENDARD_PATH, "rb"):
            css = f"""
            <style>
            @font-face {{
                font-family: 'Pretendard';
                src: url('{PRETENDARD_PATH}');
            }}
            html, body, .css-1d391kg, .stApp {{
                font-family: 'Pretendard', system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial;
            }}
            </style>
            """
    except Exception:
        # íŒŒì¼ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        css = """
        <style>
        html, body, .stApp { font-family: system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial; }
        </style>
        """
    st.markdown(css, unsafe_allow_html=True)

inject_global_css()

# -------------------------
# ìœ í‹¸ë¦¬í‹°: ì¬ì‹œë„ ìš”ì²­ ë° ì˜ˆì‹œ ë°ì´í„° ì œê³µ
def robust_get_csv(url: str, headers=None, timeout=10, retries=2) -> Tuple[pd.DataFrame, bool]:
    """
    URLì—ì„œ CSVë¥¼ ì‹œë„í•˜ì—¬ ì½ìŒ. (ì¬ì‹œë„ í—ˆìš©)
    ë°˜í™˜: (DataFrame or None, success_flag)
    """
    attempt = 0
    while attempt <= retries:
        try:
            r = requests.get(url, headers=headers, timeout=timeout)
            r.raise_for_status()
            # íŒë‹¤ìŠ¤ë¡œ ì½ê¸°
            content = r.content
            df = pd.read_csv(io.BytesIO(content))
            return df, True
        except Exception as e:
            attempt += 1
            time.sleep(1)
            if attempt > retries:
                return None, False
    return None, False

# ìºì‹œ: ì™¸ë¶€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
@st.cache_data(show_spinner=False)
def load_public_gmsl_data() -> Tuple[pd.DataFrame, bool, str]:
    """
    NASA/JPL ë˜ëŠ” ëŒ€ì²´ ì†ŒìŠ¤ì—ì„œ ì „ì§€êµ¬ í‰ê·  í•´ìˆ˜ë©´(GMSL) ì‹œê³„ì—´ì„ ì‹œë„í•˜ì—¬ ë¶ˆëŸ¬ì˜´.
    ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜.
    """
    # ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤(ìš°ì„ ìˆœìœ„)
    urls = [
        # JPL PO.DAAC / GMSL (ì‚¬ìš©ì í™˜ê²½ì— ë”°ë¼ ë‹¤ìš´ë¡œë“œ URLì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        "https://podaac.jpl.nasa.gov/dataset/NASA_SSH_GMSL_INDICATOR",
        # DataHub core sea-level-rise (CSV ì œê³µ)
        "https://datahub.io/core/sea-level-rise/r/sea-level-rise.csv",
        # Kaggle mirror (ì½ê¸° ë¶ˆê°€ ê°€ëŠ¥ì„± ìˆìŒ)
        "https://raw.githubusercontent.com/datasets/global-sea-level/master/data/observations.csv",
    ]
    for url in urls:
        df, ok = robust_get_csv(url)
        if ok and isinstance(df, pd.DataFrame):
            # í‘œì¤€í™”: date, value
            # ë‹¤ì–‘í•œ ì»¬ëŸ¼ ì´ë¦„ ëŒ€ì‘
            df_cols = [c.lower() for c in df.columns]
            # try to find year/month/date and sea level value
            if "year" in df_cols and "gmsl" in df_cols:
                # custom handling
                d = df.copy()
                if "month" in df_cols:
                    d["date"] = pd.to_datetime(d["year"].astype(int).astype(str) + "-" + d["month"].astype(int).astype(str) + "-01", errors="coerce")
                else:
                    d["date"] = pd.to_datetime(d["year"].astype(int).astype(str) + "-01-01", errors="coerce")
                # pick gmsl or 'sea_level' columns heuristically
                val_col = None
                for cand in df.columns:
                    if "gmsl" in cand.lower() or "sea_level" in cand.lower() or "absolute" in cand.lower():
                        val_col = cand
                        break
                if val_col is None:
                    val_col = df.columns[-1]
                d = d[["date", val_col]].rename(columns={val_col: "value"})
                d = d.dropna(subset=["date", "value"])
                return d, True, url
            # generic: look for a 'date' like column
            date_col = None
            for c in df.columns:
                if "date" in c.lower() or "year" in c.lower():
                    date_col = c
                    break
            value_col = None
            for c in df.columns:
                if "sea" in c.lower() and ("level" in c.lower() or "gmsl" in c.lower()):
                    value_col = c
                    break
            if date_col is None:
                # try first col as date
                date_col = df.columns[0]
            if value_col is None:
                # try last col
                value_col = df.columns[-1]
            d = df[[date_col, value_col]].copy()
            d.columns = ["date", "value"]
            # try parse date
            try:
                d["date"] = pd.to_datetime(d["date"])
            except Exception:
                # if year-only
                try:
                    d["date"] = pd.to_datetime(d["date"].astype(int).astype(str) + "-01-01")
                except Exception:
                    pass
            d = d.dropna(subset=["date", "value"])
            return d, True, url
    # ëª¨ë‘ ì‹¤íŒ¨ -> ì˜ˆì‹œ ë°ì´í„° ìƒì„± (ì—°ë„ë³„ GMSL 1880~2024 ê°€ìƒì¹˜)
    years = np.arange(1880, 2025)
    # ëˆ„ì  ì¶”ì„¸ ë‚œìˆ˜ ê¸°ë°˜ (ì˜ˆì‹œìš©)
    base = (years - 1880) * 0.2  # ë‹¨ìˆœ ëˆ„ì  ì˜ˆì‹œ
    noise = np.random.normal(loc=0.0, scale=0.5, size=len(years))
    values = base + noise
    d = pd.DataFrame({"date": pd.to_datetime(years.astype(str) + "-01-01"), "value": values})
    return d, False, "ì˜ˆì‹œ ë°ì´í„°(ë‚´ì¥)"

@st.cache_data(show_spinner=False)
def load_psmsl_station(korean_station_name: str = "MASAN") -> Tuple[pd.DataFrame, bool, str]:
    """
    PSMSLì—ì„œ íŠ¹ì • ê´€ì¸¡ì†Œ(ì˜ˆì‹œ: MASAN) ì‹œê³„ì—´ ë‹¤ìš´ë¡œë“œ ì‹œë„.
    ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ê´€ì¸¡ì†Œ ë°ì´í„° ë°˜í™˜.
    """
    # PSMSL station pages provide downloads; use known station file path pattern if available
    # ì˜ˆì‹œ: https://psmsl.org/data/obtaining/stations/2044.php (MASAN)
    # í•˜ì§€ë§Œ ì•ˆì •ì  CSV URLì€ ë³´ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‹œë„ í›„ ì‹¤íŒ¨í•˜ë©´ ì˜ˆì‹œ ë°ì´í„° ìƒì„±
    # ì‹œë„ URL (station id may vary)
    try_urls = [
        "https://psmsl.org/data/obtaining/stations/2044.php",  # MASAN page (html)
        "https://psmsl.org/data/psmsl.csv"  # placeholder
    ]
    for url in try_urls:
        df, ok = robust_get_csv(url)
        if ok and isinstance(df, pd.DataFrame):
            # try to standardize
            cols = df.columns
            if len(cols) >= 2:
                d = df.iloc[:, :2].copy()
                d.columns = ["date", "value"]
                try:
                    d["date"] = pd.to_datetime(d["date"])
                except Exception:
                    pass
                d = d.dropna(subset=["date", "value"])
                return d, True, url
    # ì‹¤íŒ¨ -> ì˜ˆì‹œ: ëŒ€í•œë¯¼êµ­ ì—°ì•ˆ(2004-2023) ì›”ë³„ ê°€ìƒì¹˜(ë˜ëŠ” ì—°ê°„)
    rng = pd.date_range(start="2004-01-01", end="2023-12-01", freq="MS")
    # ê°€ë²¼ìš´ ìƒìŠ¹ ì¶”ì„¸ (mm ë‹¨ìœ„)
    trend = np.linspace(0, 30, len(rng))  # ì´ 30mm ìƒìŠ¹ ì˜ˆì‹œ
    seasonal = 5 * np.sin(np.linspace(0, 4 * np.pi, len(rng)))
    noise = np.random.normal(0, 2, len(rng))
    values = trend + seasonal + noise
    d = pd.DataFrame({"date": rng, "value": values})
    return d, False, "ì˜ˆì‹œ ëŒ€í•œë¯¼êµ­ ì—°ì•ˆ ë°ì´í„°(ë‚´ì¥)"

# -------------------------
# ì‚¬ìš©ì ì…ë ¥(í”„ë¡¬í”„íŠ¸ ê¸°ë°˜) ë°ì´í„°: ì‚¬ìš©ìê°€ ì œê³µí•œ 'ë³´ê³ ì„œ ê³„íší‘œ' í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ
# - ì‹¤ì œ CSV/ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ê·œì¹™ì— ë”°ë¼ 'ì…ë ¥ ì„¹ì…˜'ì˜ ì„¤ëª…ë§Œ ì‚¬ìš©í•´ ë‚´ë¶€ ì˜ˆì‹œ CSV ìƒì„±
# (ì•± ì‹¤í–‰ ì¤‘ íŒŒì¼ ì—…ë¡œë“œ/ì…ë ¥ ìš”êµ¬ ê¸ˆì§€)
@st.cache_data(show_spinner=False)
def load_user_input_data() -> dict:
    """
    í”„ë¡¬í”„íŠ¸ì˜ Input ì„¹ì…˜(ë³´ê³ ì„œ ê³„íší‘œ)ì— ìˆëŠ” ì„¤ëª…ë§Œ ì‚¬ìš©í•˜ì—¬ ë‚´ë¶€ ì˜ˆì‹œ ë°ì´í„° ìƒì„±.
    ìƒì„± ë°ì´í„°:
      - korea_sealevel_20y: ì§€ë‚œ 20ë…„(2004-2023) ì—°í‰ê·  í•´ìˆ˜ë©´(mm) ë° ì—°í‰ê·  ê¸°ì˜¨(Â°C) ê°€ìƒ ë°ì´í„°
      - youth_survey: ì²­ì†Œë…„ ê¸°í›„ ë¶ˆì•ˆ ì„¤ë¬¸ ë¹„ìœ¨(ì˜ˆì‹œ: ë§¤ìš°ê·¸ë ‡ë‹¤/ê·¸ë ‡ë‹¤/ëŠë¼ì§€ì•ŠìŒ)
      - youth_future_jobs: ì²­ì†Œë…„ ë¯¸ë˜ ì§ì—…ì— ëŒ€í•œ ê¸°í›„ ì¸ì‹ ì„¤ë¬¸(ë²”ì£¼ë³„ ê°€ì¤‘ì¹˜ ì˜ˆì‹œ)
      - country_compare: êµ­ê°€ë³„ í•´ìˆ˜ë©´ ìƒìŠ¹ ì˜ˆìƒì¹˜(ì˜ˆì‹œ)
    """
    # 1) ëŒ€í•œë¯¼êµ­ í•´ìˆ˜ë©´ ë³€í™” ì¶”ì´ (ì—°ê°„)
    years = np.arange(2004, 2024)
    # ê°€ìƒì˜ ì—°í‰ê·  í•´ìˆ˜ë©´(mm, ìƒëŒ€ê°’), ì˜¨ë„(Â°C)
    # ì‚¬ìš©ìê°€ ë¬¸ì„œì—ì„œ 'ì§€ë‚œ 20ë…„ê°„ ê¸°ì˜¨ì— ë”°ë¥¸ í•´ìˆ˜ë©´ ìƒìŠ¹ ë³€í™”' ìš”êµ¬ -> ìƒì„± ì‹œ ìƒê´€ê´€ê³„ ë°˜ì˜
    temp = 13.0 + 0.03 * (years - 2004) + np.random.normal(0, 0.1, len(years))  # í‰ê· ê¸°ì˜¨ ê°€ë²¼ìš´ ìƒìŠ¹
    sealevel = 0.0 + 2.0 * (years - 2004) + (temp - temp.mean()) * 5 + np.random.normal(0, 3, len(years))
    korea_sealevel_20y = pd.DataFrame({"date": pd.to_datetime(years.astype(str) + "-01-01"), "value_mm": sealevel, "temp_c": temp})
    # 2) ì²­ì†Œë…„ ì„¤ë¬¸(ë¹„ìœ¨)
    youth_survey = pd.DataFrame({
        "ì‘ë‹µ": ["ë§¤ìš° ê·¸ë ‡ë‹¤", "ê·¸ë ‡ë‹¤", "ë¶ˆì•ˆê°ì„ ëŠë¼ì§€ ì•ŠëŠ”ë‹¤"],
        "ë¹„ìœ¨": [24.8, 51.5, 23.7]
    })
    # 3) ì²­ì†Œë…„ ë¯¸ë˜ ì§ì—…ì— ëŒ€í•œ ê¸°í›„ìœ„ê¸° ì¸ì‹ (ì˜ˆì‹œ í•­ëª©)
    youth_future_jobs = pd.DataFrame({
        "ì˜í–¥_ì •ë„": ["ë§¤ìš° ì˜í–¥", "ì•½ê°„ ì˜í–¥", "ì˜í–¥ ì—†ìŒ", "ëª¨ë¦„"],
        "ì‘ë‹µìˆ˜": [420, 310, 150, 70]
    })
    # 4) êµ­ê°€ë³„ í•´ìˆ˜ë©´ ìƒìŠ¹ ì˜ˆìƒì¹˜(ì˜ˆì‹œ ë§‰ëŒ€ê·¸ë˜í”„)
    country_compare = pd.DataFrame({
        "êµ­ê°€": ["ëŒ€í•œë¯¼êµ­", "í˜¸ì£¼", "ë¯¸êµ­", "ì¸ë„ë„¤ì‹œì•„", "ëª°ë””ë¸Œ"],
        "ì˜ˆìƒ_ìƒìŠ¹_cm_2100": [50, 60, 45, 75, 120]
    })
    return {
        "korea_sealevel_20y": korea_sealevel_20y,
        "youth_survey": youth_survey,
        "youth_future_jobs": youth_future_jobs,
        "country_compare": country_compare
    }

# -------------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ê³µê°œ ë°ì´í„°)
public_gmsl_df, public_gmsl_ok, public_gmsl_source = load_public_gmsl_data()
psmsl_df, psmsl_ok, psmsl_source = load_psmsl_station()

# ì „ì²˜ë¦¬ ê³µí†µ í•¨ìˆ˜
def preprocess_timeseries(df: pd.DataFrame, date_col="date", value_col="value") -> pd.DataFrame:
    d = df.copy()
    # í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
    d = d.rename(columns={date_col: "date", value_col: "value"})
    # í˜•ë³€í™˜
    d["date"] = pd.to_datetime(d["date"], errors="coerce")
    # ê²°ì¸¡ ì œê±°
    d = d.dropna(subset=["date", "value"])
    # ì¤‘ë³µ ì œê±°: ë‚ ì§œ ê¸°ì¤€ í‰ê· 
    d = d.groupby("date", as_index=False).agg({"value": "mean"})
    # ë¯¸ë˜ ë°ì´í„° ì œê±° (ì˜¤ëŠ˜ ì´í›„)
    d = d.loc[d["date"] <= TODAY]
    # ì •ë ¬
    d = d.sort_values("date")
    return d

# ê³µìš© ì „ì²˜ë¦¬
if isinstance(public_gmsl_df, pd.DataFrame):
    public_gmsl_df = preprocess_timeseries(public_gmsl_df, date_col="date", value_col="value")
else:
    public_gmsl_df = pd.DataFrame(columns=["date", "value"])

if isinstance(psmsl_df, pd.DataFrame):
    psmsl_df = preprocess_timeseries(psmsl_df, date_col="date", value_col="value")
else:
    psmsl_df = pd.DataFrame(columns=["date", "value"])

# ì‚¬ìš©ì ì…ë ¥(í”„ë¡¬í”„íŠ¸) ë°ì´í„° ë¡œë“œ
user_data = load_user_input_data()

# -------------------------
# ì¸í„°í˜ì´ìŠ¤: ì‚¬ì´ë“œë°”(í•„í„° ìë™ êµ¬ì„±)
st.sidebar.title("ëŒ€ì‹œë³´ë“œ ì˜µì…˜")
data_choice = st.sidebar.radio("í‘œì‹œ ë°ì´í„° ì„ íƒ", ("ê³µê°œ ë°ì´í„°: ì „ì§€êµ¬ í‰ê·  í•´ìˆ˜ë©´", "ê³µê°œ ë°ì´í„°: êµ­ë‚´ ì—°ì•ˆ ê´€ì¸¡ì†Œ(ì˜ˆì‹œ)", "ì‚¬ìš©ì ì…ë ¥(ë³´ê³ ì„œ ê¸°ë°˜)"))

# ë‚ ì§œ ë²”ìœ„ í•„í„° (ìë™ êµ¬ì„±)
if data_choice == "ê³µê°œ ë°ì´í„°: ì „ì§€êµ¬ í‰ê·  í•´ìˆ˜ë©´":
    if not public_gmsl_df.empty:
        min_d, max_d = public_gmsl_df["date"].min(), public_gmsl_df["date"].max()
    else:
        min_d, max_d = pd.to_datetime("1880-01-01"), TODAY
elif data_choice == "ê³µê°œ ë°ì´í„°: êµ­ë‚´ ì—°ì•ˆ ê´€ì¸¡ì†Œ(ì˜ˆì‹œ)":
    if not psmsl_df.empty:
        min_d, max_d = psmsl_df["date"].min(), psmsl_df["date"].max()
    else:
        min_d, max_d = pd.to_datetime("2004-01-01"), pd.to_datetime("2023-12-01")
else:
    # ì‚¬ìš©ì ë°ì´í„°(ëŒ€í•œë¯¼êµ­ 2004-2023)
    korea_df = user_data["korea_sealevel_20y"]
    min_d, max_d = korea_df["date"].min(), korea_df["date"].max()

# ì‚¬ì´ë“œë°”: ê¸°ê°„ ì„ íƒ
start_date = st.sidebar.date_input("ì‹œì‘ì¼", min_value=min_d.date(), max_value=max_d.date(), value=min_d.date())
end_date = st.sidebar.date_input("ì¢…ë£Œì¼", min_value=min_d.date(), max_value=max_d.date(), value=max_d.date())
if start_date > end_date:
    st.sidebar.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ë¹ ë¥´ê²Œ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
# ìŠ¤ë¬´ë”© ì˜µì…˜ (ì´ë™í‰ê· )
smoothing = st.sidebar.slider("ì´ë™í‰ê·  ìœˆë„ìš°(ê°œì›”)", min_value=1, max_value=24, value=3)

# -------------------------
# ë©”ì¸: í—¤ë”
st.title("ğŸŒŠğŸ« ë‚´ì¼ì€ ë¬¼ ìœ„ì˜ í•™êµ? â€” í•´ìˆ˜ë©´ ìƒìŠ¹ ëŒ€ì‹œë³´ë“œ")
st.markdown(
    """
    **ì„¤ëª…:** ì´ ëŒ€ì‹œë³´ë“œëŠ” ê³µì‹ ê³µê°œ ë°ì´í„°(NASA/PSMSL/êµ­ë‚´ ì˜¤í”ˆë°ì´í„°)ë¥¼ ë¨¼ì € ì‹œë„í•˜ì—¬ ì‹œê°í™”í•œ ë’¤,
    ì‚¬ìš©ìê°€ ì…ë ¥(í”„ë¡¬í”„íŠ¸ë¡œ ì œê³µí•œ ë³´ê³ ì„œ ê³„íší‘œ)í•œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë³„ë„ì˜ ëŒ€ì‹œë³´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ëª¨ë“  ë¼ë²¨ê³¼ UIëŠ” í•œêµ­ì–´ë¡œ ì œê³µë©ë‹ˆë‹¤.
    """
)

# ê³µê°œ ë°ì´í„° ì„¹ì…˜
st.header("1. ê³µì‹ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ (ìë™ ì—°ê²° ì‹œë„)")
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ì „ì§€êµ¬ í‰ê·  í•´ìˆ˜ë©´ (GMSL) â€” NASA/JPL ë“±")
    if public_gmsl_ok:
        st.success(f"ê³µê°œ ë°ì´í„° ë¡œë“œ ì„±ê³µ (ì¶œì²˜ ìë™ ê°ì§€): {public_gmsl_source}")
    else:
        st.warning("ê³µê°œ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ **ì˜ˆì‹œ ë°ì´í„°**ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤. (ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì†ŒìŠ¤ ë¬¸ì œ)")
        st.info("ì¶œì²˜(ì°¸ê³ ): NASA Sea Level Change Portal / DataHub / ê¸°íƒ€. ì‹¤ì œ ì‘ì—… ì‹œ ì•ˆì •ì  URLì„ ì„¤ì •í•˜ì„¸ìš”.")
    # í•„í„° ì ìš©
    df_show = public_gmsl_df.copy()
    if not df_show.empty:
        mask = (df_show["date"] >= pd.to_datetime(start_date)) & (df_show["date"] <= pd.to_datetime(end_date))
        df_show = df_show.loc[mask]
        # ì´ë™í‰ê· 
        if smoothing > 1:
            df_show["value_smooth"] = df_show["value"].rolling(window=smoothing, min_periods=1, center=False).mean()
        else:
            df_show["value_smooth"] = df_show["value"]
        # í”Œë¡¯
        fig = px.line(df_show, x="date", y=["value", "value_smooth"], labels={"value": "ì›ì‹œê°’", "value_smooth": f"{smoothing}ê°œì›” ì´ë™í‰ê· ", "date":"ë‚ ì§œ"}, title="ì „ì§€êµ¬ í‰ê·  í•´ìˆ˜ë©´ ì‹œê³„ì—´")
        fig.update_layout(legend_title_text="ë°ì´í„°")
        st.plotly_chart(fig, use_container_width=True)
        # í‘œ ë° ë‹¤ìš´ë¡œë“œ
        st.markdown("#### ë°ì´í„° í‘œ (ì „ì²˜ë¦¬ëœ ë°ì´í„°)")
        st.dataframe(df_show.rename(columns={"date":"ë‚ ì§œ","value":"ê°’","value_smooth":"ì´ë™í‰ê· "}).reset_index(drop=True).head(50))
        csv = df_show.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ì „ì²˜ë¦¬ëœ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="public_gmsl_preprocessed.csv", mime="text/csv")
    else:
        st.info("í‘œì‹œí•  ê³µê°œ GMSL ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with col2:
    st.subheader("ë°ì´í„° ì—°ê²° ì •ë³´")
    st.markdown(f"- ì „ì§€êµ¬ í‰ê·  ë°ì´í„° ì†ŒìŠ¤: `{public_gmsl_source}`")
    st.markdown(f"- PSMSL(ê´€ì¸¡ì†Œ) ì†ŒìŠ¤ ì˜ˆì‹œ: `{psmsl_source}`")
    st.markdown("- API ì‹¤íŒ¨ ì‹œ: ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë©ë‹ˆë‹¤.")
    st.markdown("**ì°¸ê³ (ë°ì´í„° ì¶œì²˜ ì˜ˆì‹œ)**:")
    st.markdown("""
    - NASA Sea Level Change Portal (ì‹œê³„ì—´/ì‹œë‚˜ë¦¬ì˜¤): sealevel.nasa.gov  
    - PSMSL (tide gauge): psmsl.org  
    - NOAA Sea Level Rise Viewer data: coast.noaa.gov/slrdata/
    """)

# ê³µê°œ ë°ì´í„°: ê´€ì¸¡ì†Œ (êµ­ë‚´ ì—°ì•ˆ ì˜ˆì‹œ)
st.header("2. ê³µê°œ ë°ì´í„°: êµ­ë‚´ ì—°ì•ˆ ê´€ì¸¡(ì˜ˆì‹œ) â€” PSMSL / KHOA ì—°ê³„")
st.markdown("êµ­ë‚´ ê´€ì¸¡ì†Œ ë°ì´í„°(ì˜ˆì‹œ)ëŠ” PSMSLì—ì„œ ì œê³µë˜ëŠ” ê´€ì¸¡ì†Œ ë°ì´í„°ë¥¼ ì‹œë„í•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
if psmsl_ok:
    st.success(f"ê´€ì¸¡ì†Œ ë°ì´í„° ë¡œë“œ ì„±ê³µ (ì¶œì²˜): {psmsl_source}")
else:
    st.warning("ê´€ì¸¡ì†Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ â€” ì˜ˆì‹œ ëŒ€í•œë¯¼êµ­ ì—°ì•ˆ ë°ì´í„°ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

if not psmsl_df.empty:
    mask = (psmsl_df["date"] >= pd.to_datetime(start_date)) & (psmsl_df["date"] <= pd.to_datetime(end_date))
    psmsl_show = psmsl_df.loc[mask].copy()
    if smoothing > 1:
        psmsl_show["value_smooth"] = psmsl_show["value"].rolling(window=smoothing, min_periods=1).mean()
    else:
        psmsl_show["value_smooth"] = psmsl_show["value"]
    fig2 = px.line(psmsl_show, x="date", y=["value", "value_smooth"], labels={"value":"ì›ì‹œê°’(mm)","value_smooth":f"{smoothing}ê°œì›” ì´ë™í‰ê· ","date":"ë‚ ì§œ"}, title="êµ­ë‚´ ì—°ì•ˆ ê´€ì¸¡ì†Œ í•´ìˆ˜ë©´(ì˜ˆì‹œ) ì‹œê³„ì—´")
    st.plotly_chart(fig2, use_container_width=True)
    csv2 = psmsl_show.to_csv(index=False).encode('utf-8-sig')
    st.download_button("êµ­ë‚´ ê´€ì¸¡ì†Œ ì „ì²˜ë¦¬ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ", data=csv2, file_name="korea_psmsl_preprocessed.csv", mime="text/csv")
else:
    st.info("êµ­ë‚´ ê´€ì¸¡ì†Œ(PSMSL) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------
# ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ (í”„ë¡¬í”„íŠ¸ ì„¤ëª… ê¸°ë°˜)
st.header("3. ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ (ë³´ê³ ì„œ ê³„íší‘œ ê¸°ë°˜)")
st.markdown("ì•„ë˜ ì‹œê°í™”ëŠ” ì‚¬ìš©ìê°€ ì œê³µí•œ **ë³´ê³ ì„œ ê³„íší‘œ(í…ìŠ¤íŠ¸)**ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìë™ ìƒì„±í•œ ì˜ˆì‹œ ë°ì´í„°ì— ë”°ë¥¸ ì‹œê°í™”ì…ë‹ˆë‹¤. ì‹¤ì œ CSV/ì´ë¯¸ì§€ë¥¼ ì œê³µí•˜ë©´ í•´ë‹¹ ë°ì´í„°ë¡œ ëŒ€ì²´í•´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# 3-1 ëŒ€í•œë¯¼êµ­ í•´ìˆ˜ë©´ ë³€í™” ì¶”ì´ (ì§€ë‚œ 20ë…„) â€” êº¾ì€ì„  + ì˜¨ë„ ìƒê´€
st.subheader("ëŒ€í•œë¯¼êµ­ í•´ìˆ˜ë©´ ë³€í™” ì¶”ì´ (2004â€“2023) â€” ì˜¨ë„ì™€ ë¹„êµ")
kdf = user_data["korea_sealevel_20y"].copy()
# ì„ íƒ ê¸°ê°„ í•„í„°
mask = (kdf["date"] >= pd.to_datetime(start_date)) & (kdf["date"] <= pd.to_datetime(end_date))
kdf = kdf.loc[mask]
if smoothing > 1:
    kdf["value_mm_smooth"] = kdf["value_mm"].rolling(window=smoothing, min_periods=1).mean()
else:
    kdf["value_mm_smooth"] = kdf["value_mm"]
# Plot: dual axis (Plotly express workaround: make secondary y via update)
fig3 = px.line(kdf, x="date", y="value_mm_smooth", labels={"value_mm_smooth":"í•´ìˆ˜ë©´ ë³€í™” (mm)","date":"ì—°ë„"}, title="ëŒ€í•œë¯¼êµ­ ì—°ì•ˆ: ì—°í‰ê·  í•´ìˆ˜ë©´ ë³€í™” (ì˜ˆì‹œ)")
fig3.add_scatter(x=kdf["date"], y=kdf["temp_c"], mode="lines", name="ì—°í‰ê· ê¸°ì˜¨(Â°C)", yaxis="y2")
fig3.update_layout(
    yaxis=dict(title="í•´ìˆ˜ë©´ ë³€í™” (mm)"),
    yaxis2=dict(title="ì—°í‰ê· ê¸°ì˜¨ (Â°C)", overlaying="y", side="right"),
    legend_title_text="ì§€í‘œ",
)
st.plotly_chart(fig3, use_container_width=True)
st.markdown("**í•´ì„(ì˜ˆì‹œ):** ì˜¨ë„ê°€ ì„œì„œíˆ ìƒìŠ¹í•¨ì— ë”°ë¼(ìš°ì¸¡ ì¶•) í•´ìˆ˜ë©´ë„ ì¥ê¸°ì ìœ¼ë¡œ ìƒìŠ¹ ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤. ì²­ì†Œë…„Â·ì§€ì—­ì‚¬íšŒ ì˜í–¥ ë¶„ì„ì˜ ê¸°ì´ˆ ìë£Œë¡œ í™œìš©í•˜ì„¸ìš”.")
csv_korea = kdf.to_csv(index=False).encode('utf-8-sig')
st.download_button("ëŒ€í•œë¯¼êµ­ í•´ìˆ˜ë©´(ë³´ê³ ì„œ ê¸°ë°˜) CSV ë‹¤ìš´ë¡œë“œ", data=csv_korea, file_name="korea_sealevel_2004_2023.csv", mime="text/csv")

# 3-2 êµ­ê°€ë³„ í•´ìˆ˜ë©´ ìƒìŠ¹ ì˜ˆìƒì¹˜ â€” ë§‰ëŒ€ê·¸ë˜í”„
st.subheader("êµ­ê°€ë³„ í•´ìˆ˜ë©´ ìƒìŠ¹ ì˜ˆìƒì¹˜ ë¹„êµ (ì˜ˆì‹œ)")
country_df = user_data["country_compare"]
fig4 = px.bar(country_df, x="êµ­ê°€", y="ì˜ˆìƒ_ìƒìŠ¹_cm_2100", labels={"ì˜ˆìƒ_ìƒìŠ¹_cm_2100":"2100ë…„ ì˜ˆìƒ ìƒìŠ¹ (cm)"}, title="êµ­ê°€ë³„ í•´ìˆ˜ë©´ ìƒìŠ¹ ì˜ˆìƒì¹˜ (ì˜ˆì‹œ)")
st.plotly_chart(fig4, use_container_width=True)
csv_country = country_df.to_csv(index=False).encode('utf-8-sig')
st.download_button("êµ­ê°€ë³„ ì˜ˆìƒì¹˜ CSV ë‹¤ìš´ë¡œë“œ", data=csv_country, file_name="country_sea_level_projection_example.csv", mime="text/csv")

# 3-3 í”¼í•´ í†µê³„ì™€ ì‚¬ë¡€(ì²­ì†Œë…„) â€” ì›ê·¸ë˜í”„ ë° ë§‰ëŒ€ê·¸ë˜í”„
st.subheader("í”¼í•´ í†µê³„(ì²­ì†Œë…„) â€” ê¸°í›„ ë¶ˆì•ˆ ì‘ë‹µ ë¹„ìœ¨")
youth_survey = user_data["youth_survey"]
fig5 = px.pie(youth_survey, names="ì‘ë‹µ", values="ë¹„ìœ¨", title="ê¸°í›„ìœ„ê¸°ë¡œ ì¸í•œ ë¶ˆì•ˆê° ë¹„ìœ¨(ì²­ì†Œë…„, ì˜ˆì‹œ)")
st.plotly_chart(fig5, use_container_width=True)
st.markdown("**ì„¤ëª…(ë³´ê³ ì„œ ê¸°ë°˜):** ì €ì†Œë“ì¸µ ì–´ë¦°ì´Â·ì²­ì†Œë…„ì˜ 76.3%ê°€ ê¸°í›„ìœ„ê¸° ë•Œë¬¸ì— ë¶ˆì•ˆê°ì„ ëŠë‚€ë‹¤ëŠ” ì¡°ì‚¬(ë³´ê³ ì„œ ì˜ˆì‹œ)ë¥¼ ë°˜ì˜í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤.")

st.subheader("ì²­ì†Œë…„: ê¸°í›„ìœ„ê¸°ê°€ ë¯¸ë˜ ì§ì—…/ì§„ë¡œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ì˜ˆì‹œ)")
yfj = user_data["youth_future_jobs"]
fig6 = px.bar(yfj, x="ì˜í–¥_ì •ë„", y="ì‘ë‹µìˆ˜", labels={"ì‘ë‹µìˆ˜":"ì‘ë‹µ ìˆ˜", "ì˜í–¥_ì •ë„":"ì˜í–¥ ì •ë„"}, title="ì²­ì†Œë…„ì˜ ê¸°í›„ìœ„ê¸° ì¸ì‹(ë¯¸ë˜ ì§ì—…ì— ëŒ€í•œ ì˜í–¥, ì˜ˆì‹œ)")
st.plotly_chart(fig6, use_container_width=True)
csv_youth = yfj.to_csv(index=False).encode('utf-8-sig')
st.download_button("ì²­ì†Œë…„ ì„¤ë¬¸(ì˜ˆì‹œ) CSV ë‹¤ìš´ë¡œë“œ", data=csv_youth, file_name="youth_survey_example.csv", mime="text/csv")

# 3-4 í…ìŠ¤íŠ¸ ìš”ì•½(ë³´ê³ ì„œ í…œí”Œë¦¿) â€” ë³´ê³ ì„œ ì œëª© ë° ì„œë¡ /ê²°ë¡  í…œí”Œë¦¿ ì œê³µ
st.header("4. ë³´ê³ ì„œ ì‘ì„± ë„ì›€: í…œí”Œë¦¿ (ì œëª©Â·ì„œë¡ Â·ê²°ë¡  ì˜ˆì‹œ)")
st.markdown("**ë³´ê³ ì„œ ì œëª©(ê°€ì œ)**: ğŸŒŠğŸ« ë‚´ì¼ì€ ë¬¼ ìœ„ì˜ í•™êµ? : ğŸš¨ í•´ìˆ˜ë©´ ìƒìŠ¹ì˜ ê²½ê³ ")
st.subheader("ì„œë¡  (ì˜ˆì‹œ)")
st.write(
    "ìµœê·¼ ê¸°í›„ì´ìƒìœ¼ë¡œ í­ì—¼ ë° ìì—°ì¬í•´ê°€ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ì§€ë‚œ 30ë…„(1991â€“2020) ë™ì•ˆ í•œêµ­ ì—°ì•ˆì˜ í‰ê·  í•´ìˆ˜ë©´ì´ ì—°í‰ê·  3.03mm ì¦ê°€í•˜ì—¬ ì•½ 9.1cm ìƒìŠ¹í•œ ì—°êµ¬ ê²°ê³¼ê°€ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤. "
    "ì´ì— ë³¸ ë³´ê³ ì„œëŠ” í•´ìˆ˜ë©´ ìƒìŠ¹ì´ ì²­ì†Œë…„ ì„¸ëŒ€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥(ì‹¬ë¦¬Â·ìƒí™œÂ·ì§„ë¡œ)ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì •ì±…ì  ì œì–¸ì„ ì œì‹œí•©ë‹ˆë‹¤."
)
st.subheader("ê²°ë¡  ë° ì œì–¸ (ì˜ˆì‹œ)")
st.write(
    "í•´ìˆ˜ë©´ ìƒìŠ¹ì€ ë‹¨ìˆœí•œ ìì—°í˜„ìƒì´ ì•„ë‹ˆë¼ ê¸°í›„ìœ„ê¸°ì˜ ê²°ê³¼ì´ë©°, ì²­ì†Œë…„ì˜ ì •ì‹ ê±´ê°•Â·ì£¼ê±°Â·ì§„ë¡œì— ì¥ê¸°ì  ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. "
    "ì •ì±… ì œì–¸: (1) í•™êµ ë‚´ ê¸°í›„ ì‹¬ë¦¬ ì§€ì›ì²´ê³„ êµ¬ì¶•, (2) ì·¨ì•½ê³„ì¸µ ëŒ€ìƒ ì¬ë‚œ ì•ˆì „ë§ ê°•í™”, (3) í•´ì•ˆì§€ì—­ ì¥ê¸° ëª¨ë‹ˆí„°ë§ ë° ì´ì£¼Â·ë³´í˜¸ ì •ì±… ìˆ˜ë¦½."
)

# -------------------------
# ì¶”ê°€ ì •ë³´: Kaggle API ì¸ì¦ ì•ˆë‚´ (ìš”ì²­ì‹œ ìë™ í‘œì¶œ)
with st.expander("ğŸ” kaggle API ì‚¬ìš©/ì¸ì¦ ë°©ë²• (ì„ íƒ)"):
    st.markdown(
        """
        Kaggleì—ì„œ ë°ì´í„°ì…‹ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ë ¤ë©´ `kaggle` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        1. Kaggle ê³„ì •ì—ì„œ *My Account* -> *API*ì—ì„œ `kaggle.json`ì„ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.  
        2. Codespaces/ë¡œì»¬ í™˜ê²½ì—ì„œ `~/.kaggle/kaggle.json`ìœ¼ë¡œ ì—…ë¡œë“œí•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.  
        3. ì˜ˆ) `pip install kaggle` í›„ `kaggle datasets download -d <dataset-owner/dataset-name>` ì‚¬ìš©.  
        (ì£¼ì˜) ì´ ì•±ì€ í˜„ì¬ ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì ‘ê·¼ ê¶Œí•œì— ë”°ë¼ ì§ì ‘ kaggle ë‹¤ìš´ë¡œë“œê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.
        """
    )

# -------------------------
# ì•± í•˜ë‹¨: ë°ì´í„° ì²˜ë¦¬ ì›ì¹™ ë° ì£¼ì˜ì‚¬í•­
st.sidebar.markdown("---")
st.sidebar.header("ë°ì´í„° ì²˜ë¦¬ ì›ì¹™")
st.sidebar.markdown(
    """
    - í‘œì¤€í™”ëœ ì»¬ëŸ¼: `date`, `value` (ë˜ëŠ” ë³€í˜• ì»¬ëŸ¼)ì„ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.  
    - ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì²˜ë¦¬, í˜• ë³€í™˜, ì¤‘ë³µ ì œê±°, ë¯¸ë˜ ë‚ ì§œ(ì˜¤ëŠ˜ ì´í›„) ì œê±°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.  
    - ìºì‹±: `@st.cache_data`ë¡œ ì™¸ë¶€ í˜¸ì¶œ ìºì‹œ ì ìš©(ì¬ì‹¤í–‰ ì†ë„ í–¥ìƒ).  
    - CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í†µí•´ ì „ì²˜ë¦¬ëœ í‘œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
)

st.caption("ì•±ì—ì„œ ì œê³µëœ ì¼ë¶€ ë°ì´í„°ëŠ” ë„¤íŠ¸ì›Œí¬/API ì‹¤íŒ¨ ì‹œ ë‚´ë¶€ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ê³µê°œ ë°ì´í„° ì‚¬ìš© ì‹œì—ëŠ” ìœ„ ì£¼ì„ì˜ ì¶œì²˜ URLì„ í™•ì¸í•˜ê³  ì ì ˆí•œ ì¸ì¦ ë° íŒŒì¼ ê²½ë¡œë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
